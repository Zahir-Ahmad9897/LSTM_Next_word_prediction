# -*- coding: utf-8 -*-
"""LSTM_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Uxmu4A4aPs0zbUYxJ-xELHWhhhthXZY
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile LSTM_app.py
# import streamlit as st
# import numpy as np
# import pickle
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing.sequence import pad_sequences
# 
# # --- Load Model and Tokenizer ---
# model = load_model('/content/drive/MyDrive/LSTM_Next_Word_Prediction_Model.keras')
# 
# with open('/content/drive/MyDrive/tokenizer.pkl', 'rb') as f:
#     tokenizer = pickle.load(f)
# 
# # --- App UI ---
# st.title("ðŸ§  LSTM Next Word Prediction")
# st.write("Type a sentence and get the next predicted word.")
# 
# # User input
# input_text = st.text_input("Enter a sentence:", "")
# 
# if st.button("Predict Next Word") and input_text.strip() != "":
#     sequence = tokenizer.texts_to_sequences([input_text])[0]
#     padded = pad_sequences([sequence], maxlen=56, padding='pre')
#     prediction = model.predict(padded, verbose=0)
#     next_word_id = np.argmax(prediction)
# 
#     # Find the word
#     next_word = None
#     for word, index in tokenizer.word_index.items():
#         if index == next_word_id:
#             next_word = word
#             break
# 
#     if next_word:
#         st.success(f"**Next word prediction:** {input_text} {next_word}")
#     else:
#         st.warning("Word not found in tokenizer vocabulary.")
#

!wget -q -O - ipv4.icanhazip.com

!streamlit run LSTM_app.py & npx localtunnel --port 8501

